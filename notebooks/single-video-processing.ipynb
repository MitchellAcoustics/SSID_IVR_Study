{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "vscode": {
                    "languageId": "plaintext"
                }
            },
            "source": [
                "# Video Processing for Eye Tracking Analysis\n",
                "\n",
                "This notebook processes eye tracking data from a research study that combines video recordings with gaze tracking information. The main functions include:\n",
                "- Converting WMV video files to MP4 format\n",
                "- Processing eye tracking data from CSV files\n",
                "- Overlaying gaze positions on video recordings\n",
                "- Chopping videos based on annotation markers\n",
                "\n",
                "## Prerequisites\n",
                "\n",
                "- Required libraries: pandas, cv2 (OpenCV), numpy\n",
                "- Custom utilities from ivr_utils package\n",
                "- Access to the data directory containing participant recordings\n",
                "\n",
                "## Data Organization\n",
                "\n",
                "The code expects:\n",
                "\n",
                "- A server data directory containing:\n",
                "  - Eyetracking data in CSV format\n",
                "  - Video recordings in WMV format\n",
                "- CSV files contain columns:\n",
                "  - Timestamp: Time in milliseconds\n",
                "  - Gaze X/Y: Screen coordinates of gaze position\n",
                "  - SlideEvent: Events like \"StartMedia\"\n",
                "  - Respondent Annotations active: Used for video chopping\n",
                "\n",
                "## Potential Improvements\n",
                "Consider adding:\n",
                "- Error handling for missing or corrupted files\n",
                "- Progress indicators for long processing operations\n",
                "- Validation of input data format and content\n",
                "- Configuration options for visualization parameters\n",
                "- Memory optimization for large video files\n",
                "- Batch processing capabilities for multiple participants"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import cv2\n",
                "from pathlib import Path\n",
                "from typing import Tuple\n",
                "from ivr_utils.ivr_utils import (\n",
                "    find_participant_files,\n",
                "    convert_wmv_to_mp4,\n",
                "    pyav_timestamps,\n",
                "    process_video,\n",
                ")\n",
                "import numpy as np\n",
                "\n",
                "import logging\n",
                "\n",
                "# Configure logging with timestamp, level and message\n",
                "logging.basicConfig(\n",
                "    level=logging.DEBUG,\n",
                "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
                "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
                ")\n",
                "\n",
                "\n",
                "# Constants\n",
                "PARTICIPANT_ID = \"P48\"\n",
                "\n",
                "local_data_dir = Path.cwd().parent / \"data\"\n",
                "server_data_dir = Path(\"/Volumes/ritd-ag-project-rd01wq-tober63/SSID IVR Study 1/\")\n",
                "output_dir = local_data_dir.joinpath(\"output/2025-01-21-test/\")\n",
                "\n",
                "# Check if the server data directory exists\n",
                "assert server_data_dir.is_dir(), \"Server data directory not found\"\n",
                "\n",
                "# Create the output directory if it does not exist\n",
                "output_dir.mkdir(parents=True, exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Find Files for participant"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Scenario video directory: /Volumes/ritd-ag-project-rd01wq-tober63/SSID IVR Study 1/Eyetracking/SSID AV1/Gaze Replays\n",
                        "Found video files: [PosixPath('/Volumes/ritd-ag-project-rd01wq-tober63/SSID IVR Study 1/Eyetracking/SSID AV1/Gaze Replays/Scene_P48_ScreenRecording-1_(0,OTHER,1005).wmv')]\n",
                        "Participant CSV: /Volumes/ritd-ag-project-rd01wq-tober63/SSID IVR Study 1/Eyetracking/SSID AV1/Sensor Data/001_P48.csv\n",
                        "Participant WMV: /Volumes/ritd-ag-project-rd01wq-tober63/SSID IVR Study 1/Eyetracking/SSID AV1/Gaze Replays/Scene_P48_ScreenRecording-1_(0,OTHER,1005).wmv\n"
                    ]
                }
            ],
            "source": [
                "eyetracking_dir = server_data_dir / \"Eyetracking\"\n",
                "\n",
                "part_csv_path, part_wmv_path = find_participant_files(PARTICIPANT_ID, eyetracking_dir)\n",
                "print(f\"Participant CSV: {part_csv_path}\")\n",
                "print(f\"Participant WMV: {part_wmv_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Import csv file for participant"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/var/folders/2c/6nz52vj116lg2j09hp8_wdj80000gn/T/ipykernel_31625/3712771333.py:2: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                        "  points = pd.read_csv(part_csv_path, skiprows=lambda x: x < 26, usecols=needed_columns, engine=\"c\")\n"
                    ]
                }
            ],
            "source": [
                "needed_columns = [\"Timestamp\", \"SlideEvent\", \"Gaze X\", \"Gaze Y\", \"Respondent Annotations active\"]\n",
                "points = pd.read_csv(part_csv_path, skiprows=lambda x: x < 26, usecols=needed_columns, engine=\"c\")\n",
                "\n",
                "\n",
                "# find the \"StartMedia\" timestamp\n",
                "row = points[points[\"SlideEvent\"] == \"StartMedia\"]\n",
                "timestamp_diff = row[\"Timestamp\"].values[0]\n",
                "\n",
                "# clean the NaN in columns\n",
                "points = points.dropna(subset=[\"Gaze X\", \"Gaze Y\"])\n",
                "\n",
                "# - timestamp_diff to make the timestamp start from 0\n",
                "points[\"Timestamp\"] = points[\"Timestamp\"] - timestamp_diff"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Checking timestamps"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# av_timestamps = pyav_timestamps(output_chopping_path)\n",
                "\n",
                "# print(f\"Number of timestamps from AV (i.e. n frames): {len(av_timestamps)}\")\n",
                "# print(av_timestamps[:10])\n",
                "\n",
                "# tdiff = np.diff(av_timestamps)\n",
                "# print(tdiff[:10])\n",
                "# print(f\"Average time difference: {np.mean(tdiff)}\")\n",
                "# print(f\"Standard deviation of time difference: {np.std(tdiff)}\")\n",
                "# print(f\"Equivalent FPS {1 / (np.mean(tdiff) / 1000)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Convert WMV to MP4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-01-21 11:33:19 - INFO - Checking existing MP4 file\n",
                        "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x1087f8380] moov atom not found\n",
                        "OpenCV: Couldn't read video stream from file \"/Users/mitch/Documents/UCL/Papers_2025/SSID_IVR_Study/data/output/2025-01-21-test/output_test_variablefps.mp4\"\n",
                        "2025-01-21 11:33:19 - WARNING - Existing MP4 is invalid: Failed to open video file\n",
                        "2025-01-21 11:33:19 - INFO - Converting WMV to MP4\n",
                        "frame=19405 fps= 50 q=-0.0 size=  995584KiB time=00:37:06.64 bitrate=3662.8kbits/s speed=5.77x    \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Conversion successful\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "frame=19417 fps= 50 q=-0.0 Lsize=  995856KiB time=00:37:07.64 bitrate=3662.2kbits/s speed=5.76x    \n"
                    ]
                }
            ],
            "source": [
                "variablefps_result = convert_wmv_to_mp4(\n",
                "    part_wmv_path,\n",
                "    output_dir.joinpath(\"output_test_variablefps.mp4\"),\n",
                "    output_fps=None,\n",
                ")\n",
                "variablefps_result.print_status()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-01-21 11:39:46 - INFO - Converting WMV to MP4\n",
                        "[vf#0:0 @ 0x138623b90] More than 1000 frames duplicated45.83 bitrate=3569.0kbits/s dup=997 drop=0 speed=2.07x    \n",
                        "[vf#0:0 @ 0x138623b90] More than 10000 frames duplicated8.40 bitrate=4570.4kbits/s dup=9982 drop=0 speed=2.15x    \n",
                        "frame=66799 fps= 65 q=-0.0 size= 1202688KiB time=00:37:06.60 bitrate=4424.9kbits/s dup=47408 drop=0 speed=2.17x    \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Conversion successful\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "frame=66831 fps= 65 q=-0.0 Lsize= 1203251KiB time=00:37:07.66 bitrate=4424.8kbits/s dup=47414 drop=0 speed=2.17x    \n"
                    ]
                }
            ],
            "source": [
                "fixedfps_result = convert_wmv_to_mp4(\n",
                "    part_wmv_path,\n",
                "    output_dir.joinpath(\"output_test_fixedfps.mp4\"),\n",
                "    output_fps=30,\n",
                ")\n",
                "fixedfps_result.print_status()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Chopping and Overlaying Gaze point"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-01-21 12:40:06 - INFO - process_video - Reading video from /Users/mitch/Documents/UCL/Papers_2025/SSID_IVR_Study/data/output/2025-01-21-test/output_test_fixedfps.mp4\n",
                        "2025-01-21 12:40:06 - DEBUG - process_video - instantiating VideoWriter with /Users/mitch/Documents/UCL/Papers_2025/SSID_IVR_Study/data/output/2025-01-21-test/output_chopped_test2_fixedfps.mp4\n",
                        "2025-01-21 12:40:06 - DEBUG - process_video - Instatiating VideoWriter with /Users/mitch/Documents/UCL/Papers_2025/SSID_IVR_Study/data/output/2025-01-21-test/output_chopped_test2_fixedfps.mp4\n",
                        "2025-01-21 12:40:06 - DEBUG - process_video - Instatiating VideoWriter with /Users/mitch/Documents/UCL/Papers_2025/SSID_IVR_Study/data/output/2025-01-21-test/output_overlay_test_fixedfps.mp4\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ecac4255c2f2413ab622dd3dbb0ea811",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/3600 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-01-21 12:41:49 - DEBUG - chopping_video - releasing resources\n"
                    ]
                }
            ],
            "source": [
                "N_FRAMES_PROC = 30 * 120  # 30 fps * 60 seconds\n",
                "\n",
                "# input_video_path = result.output_path\n",
                "input_video_path = output_dir.joinpath(\"output_test_fixedfps.mp4\")\n",
                "output_chopping_path = output_dir.joinpath(\"output_chopped_test2_fixedfps.mp4\")\n",
                "output_overlay_path = output_dir.joinpath(\"output_overlay_test_fixedfps.mp4\")\n",
                "\n",
                "process_video(\n",
                "    input_video_path, output_chopping_path, output_overlay_path, points, N_FRAMES_PROC\n",
                ")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.15"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
