{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Video Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moviepy.editor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tuple\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mivr_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mivr_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_participant_files\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meditor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VideoFileClip\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Constants\u001b[39;00m\n\u001b[1;32m      9\u001b[0m PARTICIPANT_ID \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP48\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'moviepy.editor'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "from ivr_utils.ivr_utils import find_participant_files\n",
    "\n",
    "# Constants\n",
    "PARTICIPANT_ID = \"P48\"\n",
    "\n",
    "local_data_dir = Path.cwd().parent / \"data\"\n",
    "server_data_dir = Path(\n",
    "    \"/Volumes/ritd-ag-project-rd00pj-jkang71/UCL_SSID/SSID IVR Study 1\"\n",
    ")\n",
    "output_dir = server_data_dir / \"output\"\n",
    "\n",
    "assert server_data_dir.is_dir(), \"Server data directory not found\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Files for participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "eyetracking_dir = server_data_dir / \"Eyetracking\"\n",
    "\n",
    "part_csv_path, part_wmv_path = find_participant_files(PARTICIPANT_ID, eyetracking_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import csv file for participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6t/7h8wn9n92w5f24ml_bkwck9m0000gn/T/ipykernel_50360/782891080.py:1: DtypeWarning: Columns (3,4,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  points = pd.read_csv(part_csv_path, skiprows=lambda x: x < 26)\n"
     ]
    }
   ],
   "source": [
    "points = pd.read_csv(part_csv_path, skiprows=lambda x: x < 26)\n",
    "\n",
    "# find the 'StartMedia' timestamp\n",
    "row = points[points[\"SlideEvent\"] == \"StartMedia\"]\n",
    "timestamp_diff = row[\"Timestamp\"].values[0]\n",
    "\n",
    "# clean the NaN in columns\n",
    "points = points.dropna(subset=[\"Gaze X\", \"Gaze Y\"])\n",
    "\n",
    "# - timestamp_diff to make the timestamp start from 0\n",
    "points[\"Timestamp\"] = points[\"Timestamp\"] - timestamp_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to MP4 if not already found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_mp4_path = part_wmv_path.with_suffix(\".mp4\")\n",
    "assert part_mp4_path.exists(), \"MP4 does not exist, try converting the wmv file.\"\n",
    "\n",
    "# TODO: Implement mp4 conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlaying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract into utils function\n",
    "\n",
    "N_FRAMES_PROC = 30 * 60  # 30 fps * 60 seconds\n",
    "\n",
    "# read the video\n",
    "# input_video_path = \"input.mp4\"\n",
    "output_overlay_path = local_data_dir / f\"{PARTICIPANT_ID}_output_overlay_test.mp4\"\n",
    "\n",
    "video = cv2.VideoCapture(part_mp4_path.as_posix())\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# VideoWriter mp4-mp4v format\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out_overlay = cv2.VideoWriter(output_overlay_path, fourcc, fps, (width, height))\n",
    "\n",
    "# # clean the NaN in columns\n",
    "# points = points.dropna(subset=[\"Gaze X\", \"Gaze Y\"])\n",
    "\n",
    "# # - timestamp_diff to make the timestamp start from 0\n",
    "# points[\"Timestamp\"] = points[\"Timestamp\"] - timestamp_diff\n",
    "\n",
    "# loop video frames\n",
    "current_point_index = 0\n",
    "for frame_index in range(total_frames):\n",
    "    if frame_index > N_FRAMES_PROC:\n",
    "        break\n",
    "\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # time of the frame in ms\n",
    "    current_time = frame_index / fps * 1000\n",
    "\n",
    "    # check if the time has reached the next timestamp in the eyetracking csv\n",
    "    while (\n",
    "        current_point_index < len(points) - 1\n",
    "        and points[\"Timestamp\"].iloc[current_point_index + 1] <= current_time\n",
    "    ):\n",
    "        current_point_index += 1  # index=index+1\n",
    "\n",
    "    # get the coordinates corresponding to the current timestamp\n",
    "    if current_point_index < len(points):\n",
    "        row = points.iloc[current_point_index]\n",
    "        x, y = int(row[\"Gaze X\"]), int(row[\"Gaze Y\"])\n",
    "        # draw a yellow circle\n",
    "        cv2.circle(frame, (x, y), 50, (0, 250, 250), -1)\n",
    "\n",
    "    out_overlay.write(frame)\n",
    "\n",
    "video.release()\n",
    "out_overlay.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Chopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FRAMES_PROC = 30 * 240  # 30 fps * 240 seconds\n",
    "\n",
    "# read the video\n",
    "input_path = part_mp4_path\n",
    "output_video_path = local_data_dir / f\"{PARTICIPANT_ID}_output_chopped_test.mp4\"\n",
    "\n",
    "video = cv2.VideoCapture(input_path)\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# VideoWriter\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "# # - timestamp difference\n",
    "# points[\"Timestamp\"] = points[\"Timestamp\"] - timestamp_diff\n",
    "\n",
    "# process frames\n",
    "current_point_index = 0\n",
    "skip_frames = False\n",
    "\n",
    "for frame_index in range(total_frames):\n",
    "    if frame_index > N_FRAMES_PROC:\n",
    "        break\n",
    "\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    current_time = frame_index / fps * 1000\n",
    "\n",
    "    # update current_point_index based on time\n",
    "    while (\n",
    "        current_point_index < len(points) - 1\n",
    "        and points[\"Timestamp\"].iloc[current_point_index + 1] <= current_time\n",
    "    ):\n",
    "        current_point_index += 1\n",
    "\n",
    "        # skip frames\n",
    "        if (\n",
    "            pd.isna(points[\"Respondent Annotations active\"].iloc[current_point_index])\n",
    "            or points[\"Respondent Annotations active\"].iloc[current_point_index] == \"\"\n",
    "        ):\n",
    "            skip_frames = True\n",
    "        else:\n",
    "            skip_frames = False\n",
    "\n",
    "    # write frame if not skipping\n",
    "    if not skip_frames:\n",
    "        out.write(frame)\n",
    "\n",
    "# release resources\n",
    "video.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
