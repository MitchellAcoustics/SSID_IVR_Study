---
title: A Brand New Title, Very Natural Saying Visual Perception Drives Soundscape Perception By A Lot
author:
  - name: Steve Purves
    orcid: 0000-0002-0760-5497
    corresponding: true
    email: steve@curvenote.com
    roles:
      - Investigation
      - Project administration
      - Software
      - Visualization
    affiliations:
      - University College London
  - name: Rowan Cockett
    orcid: 0000-0002-7859-8394
    corresponding: false
    roles: []
    affiliations:
      - Curvenote
keywords:
  - La Palma
  - Earthquakes
  - Soundscape
  - Immersive Virtual Reality
abstract: |
  In September 2021, a significant jump in seismic activity on the island of La Palma (Canary Islands, Spain) signaled the start of a volcanic crisis that still continues at the time of writing. Earthquake data is continually collected and published by the Instituto Geográphico Nacional (IGN). ...
plain-language-summary: |
  Earthquake data for the island of La Palma from the September 2021 eruption is found ...
key-points:
  - A web scraping script was developed to pull data from the Instituto Geogràphico Nacional into a machine-readable form for analysis
  - Earthquake events on La Palma are consistent with the presence of both mantle and crustal reservoirs.
date: last-modified
bibliography: references.bib
citation:
  container-title: Earth and Space Science
number-sections: true
---

## Introduction


Making a change here.

Based on data up to and including 1971, eruptions on La Palma happen every  years on average.

Studies of the magma systems feeding the volcano, such as @marrero2019, have proposed that there are two main magma reservoirs feeding the Cumbre Vieja volcano; one in the mantle (30-40km depth) which charges and in turn feeds a shallower crustal reservoir (10-20km depth).

Eight eruptions have been recorded since the late 1400s (@fig-timeline).

Data and methods are discussed in @sec-data-methods.

Let $x$ denote the number of eruptions in a year. Then, $x$ can be modeled by a Poisson distribution

$$
p(x) = \frac{e^{-\lambda} \lambda^{x}}{x !}
$$ {#eq-poisson}

where $\lambda$ is the rate of eruptions per year. Using @eq-poisson, the probability of an eruption in the next $t$ years can be calculated.

| Name                | Year |
|---------------------|------|
| Current             | 2021 |
| Teneguía            | 1971 |
| Nambroque           | 1949 |
| El Charco           | 1712 |
| Volcán San Antonio  | 1677 |
| Volcán San Martin   | 1646 |
| Tajuya near El Paso | 1585 |
| Montaña Quemada     | 1492 |

: Recent historic eruptions on La Palma {#tbl-history}

@tbl-history summarises the eruptions recorded since the colonization of the islands by Europeans in the late 1400s.

![Map of La Palma](figures/la-palma-map.png){#fig-map}

La Palma is one of the west most islands in the Volcanic Archipelago of the Canary Islands (@fig-map).

{{< embed notebooks/data-screening.ipynb#fig-spatial-plot >}}

@fig-spatial-plot shows the location of recent Earthquakes on La Palma.

## Data & Methods {#sec-data-methods}

### Video Processing
The method for video processing involves a systematic approach to process video frames, overlay gaze coordinates, and output processed videos. The following steps were undertaken:

1. Participant Data Preparation
The eyetracking data for participants, including timestamps, gaze coordinates and annotations for menu, was collected and stored by iMotion in CSV files. The timestamps is in milliseconds, while the gaze coordinates (Gaze X, Gaze Y) are measured from the top-left corner of the video frame.

2. Video Format Conversion
The input videos were checked to ensure compatibility with processing tools. Videos in non-MP4 formats, such as WMV, were converted to MP4 to ensure consistency and avoid compatibility issues.

3. Chopping Video
The `chopping_video` function was utilized to process and delete the video frames with menus. The process included:
    - Reading video metadata (e.g., FPS and total number of frames).
    - Iteratively reading and processing the video frames and chopping the frames with annotation.
    - Saving the resulting videos to a specified MP4 output path.


4. Overlaying Gaze Data
The `overlaying_video` function was used to annotate the video with gaze data. The process included:
    - Reading the input video and gaze data (Gaze X, Gaze Y).
    - Iterating through each frame, determining the current timestamp, and matching it with the corresponding gaze coordinates.
    - Drawing gaze annotations with colored circles on the video frames based on the gaze coordinates.


#### Implementation
The entire process was implemented in Python using pandas for handling eyetracking data, the OpenCV library for video processin and ffmpeg for video format conversion The workflow ensured that all steps were reproducible and adaptable to different datasets in csv format.



## Concluding

Adding some new lines of text to test collaboration. And more comments

## References {.unnumbered}

::: {#refs}
:::